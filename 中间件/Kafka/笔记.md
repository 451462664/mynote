# Kafka

## 初始 Kafka

### Kafka 是什么

Kafka 起初是由 LinkedIn 公司采用 Scala 语言开发的一个`多分区`，`多副本`且基于 Zookeeper 协调的分布式消息系统，现已捐献 Apache 基金会。目前 Kafka 已经定位成为一个分布式流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。

### Kafka 的历史

Kafka 的诞生式为了解决 LinkedIn 公司的数据管道问题，初期 LinkedIn 采用了 ActiveMQ 来进行数据交换，那时的 ActiveMQ 无法满足 LinkedIn 对数据传递系统的要求，经常引起各种缺陷而导致消息阻塞或者服务无法正常访问，为了能够解决这个问题 LinkedIn 决定研发自己的消息传递系统。由当时 LinkedIn 的首席架构师 Jay Kreps 组织团队进行消息传递系统的研发。

> **Kafka 名字的由来**
>
> Kafka 的架构师 Jay Kerps 对于 Kafka 名字的由来是这样讲的：由于 Jar Kerps 非常喜欢 franz kafka 并且觉得 Kafka 这个名字很酷，因此取了这个和消息传递系统完全不相干的名称 Kafka，取名并没有特别的含义。

1. 2010 年底，开源 GitHub 初始版本为 `0.7.0`。
2. 2011 年 7 月因为备受关注，被纳入 apache 孵化器项目。
3. 2012 年 10 月 Kafka 从 apache 孵化器项目毕业，成为 apache 顶级项目。
4. 2o14 年 Jay Kreps、Neha Narkhede、Jun Rao 离开 LinkedIn 成立 Confluent，从此 LinkedIn 和 Confluent 成为 Kafka 的核心贡献组织，致力于讲 Kafka 推广应用。

### Kafka 的特点

1. 同时为发布和订阅提供高吞吐量。据了解 Kafka 每秒可以生产约 25 万消息（50MB）每秒处理 55 万消息（110MB）
2. 可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费。
3. 分布式系统，易于向外扩展。所有的 prodicer、broker 和 comsumer 都会有多个，均以分布式的。无需停机即可向外扩展机器。
4. 消息被处理的状态是在 comsumer 端维护的而不是由 server 端维护，当失败时能自动平衡。
5. 支持 online 和 offline 的场景。

### Kafka 基本概念

#### 系统结构

Kafka 的体系架构包括若干 Producer、Broker、Consumer 以及一个 Zookeeper 集群。

![1616486363656](D:\Typora\image\1616486363656.png)

1. Producer：生产者，生产消息发送，负责创建消息然后将消息投递到 Kafka 中。
2. Consumer：消费者，接收生产者发送的消息，消费者链接到 Kafka 上并接收消息，进行相应的业务处理逻辑。
3. Broker：服务代理节点，可以简单地看作一个独立的 Kafka 服务器节点或 Kafka 服务实例，大多数情况下可以将 Broker 看作一台 Kafka 服务器，前提是只部署了一台 Kafka 实例。一个或多个 Broker 组成了一个 Kafka 集群。

#### 主题与分区

Kafka 中的消息以主题为单位进行归类。生产者负责将消息发送到特定的主题，而消费者负责订阅主题并进行消费。

主题可以在细粒度的划分：主题——分区——副本，可以首先细分为多个分区，一个分区只属于单个主题，通一个主题下多个分区的内容都是不一样的。

分区在存储层面可以看作是一个日志文件，消息在被追加到日志文件中的时候会分配一个特定的偏移量 `offset`。offset 是消息在分区中的唯一标识，Kafka 通过这个来保证分区内消息的顺序性，offset 并不能跨分区，不能保证主题的消息是有序的。每一条消息被发送到 broker 之前会根据分区规则选择存储到具体的分区，如果分区规则设定的合理那么消息都会被均匀的分布在不同的分区中,避免了消息都在同一台机器上造成消息读写 I/O 过大。

Kafka 又为分区引入了多副本 `Replica` 机制，通过为每个分区增加副本数量来提升容灾能力。通一个分区在不同副本中保存着相同的消息。副本是`一主多从`的关系，leader 副本负责处理读写请求，follower 副本只负责与 leader 副本的消息同步。副本都是被散落在不同的 broker 中。当 leader 出现故障时从 follower 副本中重新选举出新的 leader 副本对外提供服务。

![1616487400752](D:\Typora\image\1616487400752.png)

上图中 Kafka 集群中有 4 个 broker，其中某个主题有 3 个分区并且每个分区都有 3 个副本（1 个 leader，2 个 follower）。Producer、Consumer 只和 leader 副本进行交互，follower 副本只和 leader 同步数据。

分区中所有副本统称为 `AR`。所有与 leader 副本保持一定程度同步的副本（包括 leader 副本在内）组成 `ISR`，ISR 集合是 AR 集合中的一个子集。与 leader 副本同步滞后的副本（不包含 leader 副本）称为 OSR，所以 `AR = ISR + OSR` 在正常情况下，所有的 follower 副本都应该与 leader 副本保持同步，即 AR = ISR，OSR 为空。

### Kafka 安装与配置

安装的环境是 CentOS7 + Docker 搭建 Kafka 运行环境还需要 Zookeeper。

第一步下载 Zookeeper 和 Kafka 镜像

```shell
# 首先 kafka 依赖 zookeeper 需要先下载 zookeeper 镜像
[root@bogon ~]# docker pull wurstmeister/zookeeper
# 之后继续下载 kafka 镜像
[root@bogon ~]# docker pull wurstmeister/kafka
```

第二步启动下载的 Zookeeper 和 Kafka 镜像

```shell
# -it 是允许与容器实例进行交互的，如果不加的话容器里的连接会被拒绝
docker run -itd --name zookeeper -p 2181:2181 wurstmeister/zookeeper

# KAFKA_BROKER_ID 设置 brokerid 保持唯一
# KAFKA_ZOOKEEPER_CONNECT 设置连接 zookeeper 并在 / 下创建 kafka 文件
# KAFKA_ADVERTISED_LISTENERS 设置对外暴露的地址
# KAFKA_LISTENERS 设置对内暴露的地址
docker run -d --name kafka -p 9092:9092 --link zookeeper -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181/kafka -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.198.129:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -it wurstmeister/kafka
```

> 执行以上 docker 命令即可部署好单机的 Zookeeper 和 Kafka。在过程中如果遇到 docker run 之后容器立马停止可以使用 docker logs [容器 id]来查看日志并分析遇到的问题。

### 先跑起来看看生产与消费

在真正发送消费消息之前需要在 Kafka 创建对应的主题。

```shell
# 注意 kafka 启动后按需要创建 topic 进入容器
docker exec -it [容器 id] /bin/bash
# 查看创建的主题
./bin/kafka-topics.sh --list --zookeeper 172.17.0.2:2181/kafka
# 创建主题
# --zookeeper 指定了 Kafka 所连接的 Zookeeper 服务地址
# --topic 指定了所要创建主题的名称
# --kafka-factor 指定了副本因子
# -- partitions 指定了分区个数
./bin/kafka-topics.sh --create --zookeeper 172.17.0.2:2181/kafka --replication-factor 1 --partitions 1 --topic feiltest
```

Kafka 提供了许多实用的工具存放在 /bin 目录下。所以我们可以使用这些工具来模拟生产者与消费者。

#### 消费者

/bin 目录下有两个工具 `kafka-console-consumer.sh` 和 `kafka-console-producer.sh` 分别可以通过控制台收发消息。

```shell
# 使用 kafka-console-consumer.sh 来监听主题消息
# --bootstrap-server 指定了连接 kafka 的地址多个地址用逗号分隔
# --topic 指定了消费者订阅的主题
kafka-console-consumer.sh --bootstrap-server 172.17.0.3:9092 --topic feiltest
```

#### 生产者

```shell
# 使用 kafka-console-producer.sh 来模拟生产者发送消息
# --broker-list 指定了连接的 kafka 地址
# --topic 指定了发送消息时的主题
kafka-console-producer.sh --broker-list 172.17.0.3:9092 --topic feiltest
```

#### 生产与消费

```shell
# 生产
kafka-console-producer.sh --broker-list 172.17.0.3:9092 --topic feiltest
>hell
hello
>hello
>feil
>woshi shei
>

# 消费
kafka-console-consumer.sh --bootstrap-server 172.17.0.3:9092 --topic feiltest
hell
hello
hello
feil
woshi shei
```

### Kafka 服务端参数配置

在 docker 生成 Kafka 容器的时候有几个环境变量的配置其实就是 Kafka 服务端的参数配置，Kafka 服务端参数也并非只有这么几个，这几个只是常用配置。

1. **zookeeper.connect：**该参数表明 broker 要连接的 Zookeeper 集群的服务地址包含端口号，没有默认值是必填项。如果多个地址则用逗号来分割比如 localhost1：2181,localhost2:2181。最佳实践是在后面在加一个 chroot 路径。这样既可以表明该 chroot 路径下的节点是为 Kafka 所用的，也可以实现多个 Kafka 集群复用一套 Zookeeper 集群。比如 localhost:2181/kafka，如果不指定 chroot 那么则默认 Zookeeper 根路径。
2. **listeners：**该参数表明 broker 监听客户端连接的地址列表，即为客户端要连接 broker 的入口地址列表。配置格式为 protocol1://hostname1:prot1,protocol2://hostname2:prot2 其中 protocol 代表协议类型，Kafka 中支持的协议类型有 PLAINTEXT、SSL、SASL_SSL 等。如果没有安全需要则使用 PLAINTEXT 即可。如果不指定主机名则表示绑定默认网卡，可能会绑定到 127.0.0.1 这样就无法对外提供服务，所以主机名不要为空。如主机名是 0.0.0.0 则表示绑定所有网卡。与此参数关联的参数还有 `advertised.listeners` 作用和 listeners 类似，一般使用 advertised.listeners 参数绑定公网 ip 供外部客户端使用，而配置 listeners 参数来绑定私网 ip 供 broker 间通信。
3. **broker.id：**该参数用来指定 Kafka 集群中 broker 的唯一标识。默认值 -1 如果没有配置那么 Kafka 会自动生成一个。这个参数还和 meta.properties 文件以及服务端参数 broker.id.generation.enable 和 reserved.broker.max.id 有关。
4. log.dir 和 log.dirs：用于配置 Kafka 日志文件存放的根目录。log.dir 配置单个根目录，log.dirs 配置多个根目录。log.dirs 优先级比 log.dir 高，但是没有配置 log.dirs 则会以 log.dir 为准，默认情况下只配置了 log.dir 其默认值是 /tmp/kafka-logs。
5. message.max.bytes：该参数指定 broker 所能接收消息的最大值，默认 1000012B 约等于 976.6KB。如果生产者发送的消息大于此值会报 RecordToolLargeException 的异常。修改此参数还要考虑 max.request.size（客户端参数）、max.message.bytes（topic 端参数）等参数的影响。所以修改此参数前应该考虑拆分消息的可行性。

### 总结

1. Kafka 的基本概念、特点。
2. Kafka 的系统结构（多个 broker 连接 Zookeeper 集群、多个 producer、consumer 来连接 broker）。
3. 主题与分区的概念，一个 Topic 对应多个分区散列在 broker 上，每个分区又可以细分为多个副本（一主多从）。
4. 使用 docker 来部署单机版的 Kafka，并且使用 Kafka 的工具来模拟生产消息和消费消息。
5. 查看了 Kafka 服务端常用参数的使用方法和场景。

## Kafka 生产者

从开发的角度看，生产者就是负责像 Kafka 发送消息的应用程序，所以 Apache 提供了一套对于 Kafka 操作的 jar 工具类包。

这也是从 Kafka 0.9X 版本开始推出使用 Java 语言编写的客户端。

### Demo 案例

一般的生产者开发基本都需要以下几个步骤

1. 配置生产者需要的参数以及创建生产者的实例。
2. 构建需要发送的消息。
3. 发送消息。
4. 关闭生产者实例以释放资源。

```java
public class KafkaProducer {
    private static final String brokerList = "localhost:9092";
    private static final String topic = "topic-demo";
    
    public static Properties initConfig() {
        Properties props = new Properties();
        props.put("bootstrap.servers", brokerList);
        props.put("key.serializer", "org.apche.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apche.kafka.common.serialization.StringSerializer");
        props.put("client.id", "producer.client.id.demo");
        rteurn props;
    }
    
    public static void main(String[] args) {
        // 配置生产者需要的参数以及创建生产者的实例
        Properties props = initConfig();
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        // 构建需要发送的消息
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, "hello, Kafka!");
        // 发送消息
        try {
            producer.send(record);
        } catch (Exception e) {
            e.printStackTrace();
        }
        // 关闭生产者实例
        producer.close();
    }
}
```

对于上面的生产者 demo 发现在构建消息对象的时候 ProducerRecord 的构造器里面只传了两个参数，其实它还包含了更多的属性.

```java
public class ProducerRecord {
    private final String topic; // 主题
    private final Integer partition; // 分区号
    private final Headers headers; // 消息头部
    private final K key; // 键
    private final V value; // 值
    private final Long timestamp; // 消息的时间戳
}
```

### deomo 案例详解

#### 参数配置的技巧

一般在构建 Properties.put 属性的时候，我们无法记住所有的参数名称，只能有个大致的印象很容易拼错，所以我们可以直接使用 org.apche.kafka.clients.prodicer.ProducerConfig 类来定义。每个参数在 ProducerConfig 中都有对应的常量来对应。

在写序列化器的时候全限类名也很容易写错所以我们也可以通过 StringSerializer.class.getName() 来替代。

KafkaProducer 实例是线程安全的，所以可以在多个线程中使用通一个实例，也可以将 KafkaProducer 实例进行缓存池化来供其他线程调用。

#### 消息的发送

完成生产者实例后，接下来就是构建消息了。在上面代码中我们构建的消息实例 ProducerRecord 只传入了 topic 主题和 value 消息体，其他属性都是为 null。所以在实际企业开发中可以根据具体的使用场景来配置其他属性。

创建完消息后需要发送消息，在 Kafka 中发送消息有三种模式

1. 发后即忘（fire-and-forget）
2. 同步（sync）
3. 异步（async）

##### 发后即忘发送方式

在上面实例代码中使用的 send() 就是发后即忘的方式，也就是只管往 Kafka 中扔消息而不关心消息是否正确的到达。大多数情况下这种方式没什么问题，但是在某些对消息可靠性要求较高的场景下使用这种模式就不太合适了。虽然这种方式的性能最高，但是可靠性也是最差的。

##### 同步发送方式

KafkaProducer.send() 这个方法并非是 void 类型的，而是 Future<RecordMetadata> 类型。send() 也有重载的方法，出了消息参数，还可以定义 callback 回调参数类型。

要实现同步的方式可以利用返回的 Future 对象来实现。熟悉 Java 的应该能联想到当线程池提交任务后也是可以返回 Future 对象并且可以通过调用 get() 方法来阻塞的获取执行结果，那么 Kafka 返回的 Future 也是可以使用 get() 方法来阻塞等待 Kafka 的响应，直到消息发送成功或者发生异常。

当然 Kafka 也提供了 get(long timeout, TimeUnit unit) 方式来设置等待响应的时间，这样就可以实现非阻塞等待了，就是在比如隔一段时间 get 获取以下如果超过了时间那么就去执行其他的业务代码。

同步的方式可靠性高，要么消息被发送成功，要么发生异常进行重试。不过同步的性能相比发后即忘会差很多，需要阻塞等待一条消息发生完成后才能发送下一条。

##### 异步放松方式

上面也说了 KafkaProducer.send() 方法可以选择传入一个 callback 的回调函数。所以在 Kafka 返回响应时会调用该函数来实现异步的发送确认。

#### 释放资源

KafkaProduer.close() 方法会阻塞等待之前所有的发送请求完成后再关闭 KafkaProducer。当然 KafkaProducer 还提供了一个带超时的 close(long timeout, TimeUnit unit) 如果调用了带超时的 close() 方法，那么只会等待 timeout 时间内来完成所有尚未完成的请求处理，然后强行退出。一般调用无参的 close()。

#### 序列化

生产者发送消息的时候肯定是需要将消息体序列化成字节数组才能通过网络发送给 Kafka。消费者需要使用反序列化器把从 Kafka 中收到的消息字节数组转换为对应的对象。

在 demo 中我们使用了 StringSerializer 当然除了 String 类型的序列化器，还有 ByteArray、ByteBuffer、Bytes、Double、Integer、Long 这几种类型。他们都实现了 org.apche.kafka.common.serialization.Serializer 接口并实现了接口中的方法。

```java
public interface Serializer {
    // 用来配置当前类
    void confingure(Map<String, ?> configs, boolean isKey);
    // 用来执行序列化操作
    byte[] serialize(String topic, T data);
    void close();
}
```

当然如果我们想自定义序列化器也是只需要实现 Serializer 接口并实现里面的方式就好了，那么如何使用自定义的序列化器呢，只需要将 KafkaProducer 的 value.serializer 参数设置为自定义序列化器的全限类名即可，也就是在 props.put 中设置 value.serializer 的时候赋值。

#### 分区器

生产者在通过 send() 发送消息到 broker 的过程中，有可能需要经过定义的拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的过程才能真正的将消息发到 broker。拦截器不是必需的，但是序列化器是必需的，消息在经过序列化之后需要确定发往哪个分区。

> 注意：如果 ProducerRecord 中没有指定了 partition 字段，那么就需要依赖分区器，根据 key 这个字段来计算 partition 的值。

Kafka 中默认的分区器是 `org.apache.kafka.clients.producer.intemals.DefaultPart山oner` 它实现了 Partitioner 接口。

```java
public interface Partitioner {
    
    /**
     * 用来计算分区号返回 int 值
     * 如果 key 不为 null 那么就会根据 key 进行 hash 采用 MurmurHash2 算法，具备高性能及低碰撞率，最终得到 hash 值来	   * 计算分区号。
     * 如果 key 为 null 那么消息就会以轮询的方式发往主题内的各个分区。
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);
    
    public void close();
}
```

> 注意：如果 key 不为 null，那么计算得到的分区号会是所有分区中的任何一个；如果 key 为 null，那么计算得到的分区号仅为可用分区的任意一个。

针对上面的规则，除了使用 Kafka 提供的默认分区器，我们还可以自定义分区器来打破这个规则具体步骤：

1. 首先定义一个类实现 Partitioner 接口。
2. 之后通过配置来启用自定义分区器 porps.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, 自定义类全限类名);

#### 拦截器

拦截器是 Kafka 0.10.0.0 中引入的一个功能，Kafka 有两种拦截器一种是生产者拦截器，另外一种就是消费者拦截器。

拦截器顾名思义就拦截流程做一些事情，比如规则的过滤不符合要求的消息、修改消息内容等等，类似于 JavaWeb 中的 Filter，在请求和响应的时候进行拦截处理。Kafka 的生产者拦截器就是在发送消息之前进行拦截处理。

Kafka 中的拦截器 `org.apche.kafka.clients.producer.Producer.ProducerInterceptor` 接口。

```java
public interface ProduerInterceptor {
    
    /**
     * 在消息序列化和计算分区之前会调用生产者拦截器的 onSend() 方法来对消息进行定制化操作。一般来说最好不要修改消息 			 * ProducerRecord 的 topic、key 和 partition。如果要修改需要确保对其有准确的判断，否则会与预想的效果出现偏差，比  	  * 如修改 key 会影响分区的计算同样也会影响  broker 端日志压缩的功能。
     */
    public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);
    
    /**
     * KafkaProducer 会在消息被应答之前或消息发送失败时调用此方法，优先于用户设定的 callback 之前执行。这个方法运行在 		 * Producer 的 I/O 线程中，所有这个方法越简单越好。
    public void onAcknowledgement(RecordMetadata metadata, Exception exception);
    
    public void close();
}
```

定义完拦截器后和分区器一样都是通过 props.put() 来配置拦截器。

### 原理分析

那么在 Kafka 消息发送经历过拦截器、序列化器、分区器等一系列作用后，此后会发生的什么？

![1616937384191](D:\Typora\image\1616937384191.png)

##### 主要流程

通过上图可以看到 Kafka 服务器端消息的发送主要依赖两个线程：主线程、Sender 线程（发送线程）。

拦截器、序列化器、分区器之后有一个`消息累加器——RecordAccumulator`我们可以看到消息累加器里面有多个分区每个分区又对应着多个 ProducerBatch。通过名字大概可以知道 RecprdAccumulator 主要用来缓存通过拦截器、序列化器、分区器经过的消息以方便 Sender 线程获取到消息可以批量的发送。缓存消息的大小可以通过生产者客户端参数 `buffer.memory` 来配置，默认为 32MB。如果生产者发送的太快导致缓存空间不足就会导致在调用 send() 方法的时候要么被阻塞要么抛出异常。

RecordAccumulator 为每个分区维护着一个双端队列。队列中的元素就是 ProducerBatch，在消息写入的时候，追加到双端列队的尾部。Sender 读取消息的时候，从双端队列的头部读取消息。消息在网络中传输肯定是以字节来传输的所以在 Apache 提供的客户端中是用 nio 中的 ByteBuffer 来实现内存的创建和释放，不过频繁创建和释放是比较耗费资源的。所以在 RecordAccumulator 中有一个 BufferPool 的属性用于实现 ByteBuffer 的复用，以实现缓存的高效利用。但是 BufferPool 只管理特定大小的 ByteBuffer，这个特定大小由 batch.size 参数来指定，默认为 16KB。

Sender 在获取消息后会进一步将格式转换为 <Node, List<ProducerBatch>> 的形式，其中 Node 代表 Kafka 集群的 broker 节点，之后还会进一步细分转换为 <Node, Request> 的形式，这样就可以将 Request 请求发往各个 Node 中了。

> Request：Kafka 各种协议请求，对于消息发送而言是指具体的 ProducerRequest。

Sender 线程在发往 Kafka 之前还会保存到 InFlightRequests 中，InFlightRequests 保存对象形式为 Map<NodeId, Deque<Request>> 主要是缓存已经发出但还没有收到响应的的请求（NodeId 是一个 String 类型，表示节点的 id 编号）。InFlightRequests 还提供了许多管理类的方法，通过配置参数可以限制每个连接（客户端与 broker）之间的连接最多缓存的请求数，配置参数为 `max.in.flight.requests.per.connection` 默认为 5。即每个连接最多只能缓存 5 个未响应的请求，超过的话就不能向这个连接发送更多的请求了，除非之前缓存的请求收到了响应。

### 一些重要的生产者配置参数

| 参数名称                | 默认值   | 参数释义                                                     |
| :---------------------- | -------- | :----------------------------------------------------------- |
| acks                    | 1        | 用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。 |
| max.request.size        | 1MB      | 用来限制生产者客户端能发送消息的最大值。                     |
| retries                 | 0        | 用来配置生产者重试次数。                                     |
| retry.backoff.ms        | 100      | 设定重试之间的时间间隔。                                     |
| compression .ty pe      | none     | 用来指定消息的压缩方式。none 消息不会被压缩。                |
| connections.max.idle.ms | 540000ms | 用来指定在多久之后关闭限制的连接。                           |
| linger.ms               | 0        | 用来指定生产者发送 ProducerBatch 之前等待更多消息加入的时间。 |
| receive.buffer.bytes    | 32KB     | 用来设置 Socket 接收消息缓冲区的大小。                       |
| send.buffer.bytes       | 128KB    | 用来指定 Socket 发送消息缓冲区的大小。                       |
| request.timeout.ms      | 30000ms  | 用来配置 Producer 等待请求响应的最长时间。                   |

### 总结

主要学习了 Apache 为 Kafka 提供的操作工具包服务端代码的编写，操作类的使用与理解服务端发送消息的的编写代码流程。

通过 API 来了解从客户端发送消息需要的流程比如 send() 之后还有拦截器、序列化器、分区器，消息累加器这些都是在主线程中完成的。

还有 send() 消息的发送方式包括：发后即忘、同步发送、异步放松。

对于 KafkaProducer 来说是线程安全的，我们可以在多线程的环境中去使用它。

## Kafka 消费者

### Demo 案例

### 消费者与消费组

### 总结

## 主题与分区

主题作为消息的归类，可以在细分为分区，分区可以看作是消息的二次归类，分区的划分为 Kafka 提供了可伸缩性、水平扩展的功能，还可以通过副本机制来为 Kafka 提供数据冗余以提高数据的可靠性。

### 主题的管理

主题的管理顾名思义了就是对主题的 CRUD 操作。可以通过 Kafka 提供的 Kafka-topic.sh 脚本来执行 CRUD 这个脚本位于 /bin/目录下。

kafka.topics.sh 有五种指令类型：create、list、describe、alter。

#### 创建主题

broker 端配置参数 `auto.create.topics.enable` 设置为 true（默认值）那么生产者向一个未创建的主题发送消息时，会自动创建一个分区数为 num.partitions（默认值为 1）、副本因子 default.replication.factor（默认值为 1）的主题。或者当一个消费者开始向未知主题中读取消息时，或者当任意客户端向未知主题发送元数据请求时，都会按照配置参数 num.partitions 和 default.replication.factor 的值来创建一个相应的主题。

> 注意：除非有特殊应用需求，否则不建议将 auto.create.topics.enable 设置为 true。这个参数会增加主题管理与维护的难度。

```shell
# 创建一个名为 feiltest 分区为 4 副本为 2 的主题
kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic feiltest --partitions 4 --replication-factor 2
```

假设我们的 Kafka 机器环境有三台 broker：node1、node2、node3。brokerId 为 0、1、2。所以在执行完上面创建主题的命令后会发现三个 broker 节点一共创建了 8 个文件夹，这个数字 8 实质上是分区数 4 与副本因子 2 的乘积。

![1616945820677](D:\Typora\image\1616945820677.png)

还可以手动来指定分区副本的分配方案 `replica-assignment` 参数

```shell
--replica-assignment [brokerId_replica1: brokerId_replica2, ...]
```

这种方式根据分区号的数值从小到大顺序进行排列，分区与分区之间用逗号隔开，分区内多个副本用冒号隔开，在使用 replica-assignment 时就不需要指定 partitions 和 replication-factor 这两个参数了。

> 注意：
>
> 1. 同一个分区内的副本不能重复，比如指定了 0:0,1:1 这种。
> 2. 分区之间所指定的副本数不同也不行，比如 0:1,0,1:0 这种。
> 3. 也不能跳过分区的行为也不行，比如 0:1,,0:1 这种。

创建主题时对于主题名称存在时会抛出异常那么我们可以使用 `if-not-exists` 参数，如果在创建主题时带上这个参数，那么在发生名称冲突时将不做任何处理。

```shell
kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topicName -create --replication-factor 1 -- partitions 1 --if-not-exists
```



#### 分区副本的分配

在创建主题的时候，如果使用了 replica-assignment 参数，那么就按照指定的方案来进行分区副本的创建。如果没有使用那么就需要按照内部的逻辑来计算分配方案了。

使用 kafka-topics.sh 脚本创建主题有两种策略。（broker.rack 参数指定机架信息）

1. 未指定机架信息
2. 指定机架信息

以上两个方法核心就是遍历每个分区 partition，然后从 brokerArray（brokerId 的列表）中选取 replicationFatcor 个 brokerId 分配给这个 partition。

#### 查看主题

既然是查看主题我们就可以通过 kafka-topics.sh 脚本中的 list、describe 两个指令来操作。

```shell
# 查看所有主题
kafka-topics.sh --zookeeper localhost:2181/kafka list

# 查看指定主题
kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topicName1,topicName2

# 在使用 --describe 指令查看主题信息时还可以额外指定以下三个参数来增加一些附加功能
# topics-with-overrides：可以找出所有包含覆盖配置的主题，它只会列出包含了与集群不一样配置的主题
# under-replicated-partitions 和 unavailable-partitions 都可以找出有问题的分区，通过第一个参数可以找出所有包含失效副本的分区。（可能正在进行 leader 同步操作）也有可能发生异常。
kafka-topics.sh --zookeeper localhost:2181/kafka --desribe --topic topicName --under-replicated-partitions

# unavailable-partitions 参数可以查看主题中没有 leader 副本的分区，这些分区处于离线状态，对于外界的生产者和消费者来说处于不可用的状态
kafka-topics.sh --zookeeper localhost:2181/kafka --desribe --topic topicName --unavailable-partitions
```

#### 修改主题

主题被创建后可以进行修改，比如修改分区的个数、修改配置等，这个是 kafka-topics.sh 脚本中 alter 指令完成。

##### 增加主题分区

```shell
# 将指定 topic 分区修改为 3
kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topicName --partitions 3
```

在增加分区时应该考虑消息中包含 key 不为空时，根据 key 计算分区的行为就会收到影响，对于基于 key 的分区应该在创建主题的时候就设置好分区的数量，避免以后进行调整。

> **注意：**目前 Kafka 只支持增加分区而不支持减少分区。
>
> 实现此功能需要考虑的因素很多， 比如删除的分区中的消息该如何处理？如果随着分区一起消失则消息的可靠性得不到保障；如果需要保留则又需要考虑如何保留。 直接存储到现有分区的尾部， 消息的时间戳就不会递增， 如此对于Spark、Flink这类需要消息时间戳（事件时间）的组件将会受到影响；如果分散插入现有的分区， 那么在消息量很大的时候， 内部的数据复制会占用很大的资源 而且在复制期间， 此主题的可用性 又如何得到保障？与此同时， 顺序性问题、事务性问题， 以及分区和副本的状态机切换问题都是不得不面对的。 反观这个功能的收益点却是很低的， 如果真的需要实现此类功能， 则完全可以重新创建一个分区数较小的主题， 然后将现有主题中的消息按照既定的逻辑复制过去即可。

创建主题时通过 if-not-exists 参数来忽略异常，那么要修改的主题不存在可以通过 `if-exists` 参数来忽略异常。

```shell
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topicName --partitions 4
```

还可以继续来修改主题的配置，创建主题可以通过 config 参数来设置创建主题的相关参数，通过这参数可以覆盖原本的默认配置。在修改的时候我们可以通过 alter 指令配合 config 参数增加或修改一些配置。

```shell
# 将指定主题的 max.message.bytes 配置值从 1000 修改为 2000
kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topicName --config max.message.bytes=2000

# 接下来再次修改另一个配置 segment.bytes
kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topicName --config segment.bytes=l048577
```

有了修改 conig 当然少不了删除 config 配置，可以通过 `delete-config` 参数来删除之前的覆盖的配置，使其恢复默认值。

```shell
# 将指定主题某些配置都删除
kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topicName --delete-config segment.bytes
--delete-config max.message.bytes
```

> 在使用 kafka-topics.sh 脚本执行 alter 操作时会收到警告，指明了在 kafka-topics.sh 中的 alter 已经过期了，将来会删除，推荐使用 kafka-configs.sh 脚本来实现相关功能。

#### 配置管理

kafka.configs.sh 脚本是专门用来对配置进行操作的（在运行状态下修改原有的配置，如果达到动态变更的目的）。kafka.configs.sh 脚本不仅可以支持操作主题相关的配置，还可以支持操作 broker、用户和客户端这 3 个类型的配置。

kafka.configs.sh 脚本使用 `entity-type` 参数来指定操作配置的类型，并且使用 entity-name 参数来指定操作配置的名称。比如查看主题 feiltest 的配置如下

```shell
# --describe 指定了查看配置的指令动作
# --entity-type 指定了查看配置的实体类型 --entity-name 指定了查看配置的实体名称 entity-type 可配置 4 个值：topics、brokers、clients 和 
kafka-configs.sh --zookeeper localhost:2181/kafka --desribe --entity-type topics --entity-name feiltest
```

entity-type 和 entity-name 对应关系

| entity-type 的释义          | entity-name 的释义                                           |
| --------------------------- | ------------------------------------------------------------ |
| 主题类型的配置 topics       | 指定主题的名称                                               |
| broker 类型的配置的 brokers | 指定 brokerId 值，即 broker 中 broker.id 参数配置的值        |
| 客户端类型的配置 clients    | 指定 clientId 值，即 kafkaProducer 或 KafkaConsumer 的 client.id 参数配置的值 |
| 用户类型的配置 users        | 指定用户名                                                   |

```shell
# 使用 alter 指令变更时，需要配合 add-config 和 delete-config 两个参数一起使用。add-config 用来实现配置的增改，delete-config 参数用来实现配置的删，即删除配置恢复默认值
# 覆盖 cleaup.policy 和 max.message.bytes 属性
kafka-configs.sh --zookeeper localhost:2181/kafka --alter --entity-type tpoics --entity-name poticName --add-config cleaup.policy=compact,max.message.bytes=10000
```



### 分区的管理

### 如何选择合适自己的分区

### 总结

## 日志存储

### 文件目录布局

### 日志格式

### 日志索引

### 日志清理

### 磁盘存储

### 总结